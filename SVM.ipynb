{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvCaxWNzv4ovIrvaNfYYyv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-on_gUcJYHk"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix, roc_curve, auc, precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# Load datasets\n","eeg_data = pd.read_csv(\"/content/drive/MyDrive/eeg/final_data2.csv\")\n","participants = pd.read_csv(\"/content/drive/MyDrive/eeg/participants.tsv\", sep=\"\\t\")\n","\n","# Merge datasets\n","merged_df = eeg_data.merge(participants, on=\"participant_id\", suffixes=(\"_eeg\", \"_meta\"))\n","merged_df.drop(columns=[\"Group_eeg\"], inplace=True)\n","\n","# Encode categorical features\n","le_channel = LabelEncoder()\n","le_band = LabelEncoder()\n","le_gender = LabelEncoder()\n","le_group = LabelEncoder()\n","\n","merged_df[\"Channel\"] = le_channel.fit_transform(merged_df[\"Channel\"])\n","merged_df[\"Band\"] = le_band.fit_transform(merged_df[\"Band\"])\n","merged_df[\"Gender\"] = le_gender.fit_transform(merged_df[\"Gender\"])\n","merged_df[\"Group\"] = le_group.fit_transform(merged_df[\"Group_meta\"])\n","merged_df.drop(columns=[\"participant_id\", \"Group_meta\"], inplace=True)\n","\n","# Define features and target\n","X = merged_df.drop(columns=[\"Group\"])\n","y = merged_df[\"Group\"]\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n","\n","# Train SVM model\n","svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n","svm_model.fit(X_train, y_train)\n","\n","# Predictions\n","y_pred = svm_model.predict(X_test)\n","y_prob = svm_model.predict_proba(X_test)\n","\n","# Evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average=\"weighted\")\n","kappa = cohen_kappa_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n","sensitivity = recall\n","specificity = []\n","fdr = []\n","npv = []\n","ppv = precision\n","\n","for i in range(len(conf_matrix)):\n","    tn = conf_matrix.sum() - (conf_matrix[i, :].sum() + conf_matrix[:, i].sum() - conf_matrix[i, i])\n","    fp = conf_matrix[:, i].sum() - conf_matrix[i, i]\n","    fn = conf_matrix[i, :].sum() - conf_matrix[i, i]\n","    tp = conf_matrix[i, i]\n","\n","    specificity.append(tn / (tn + fp) if (tn + fp) != 0 else 0)\n","    fdr.append(fp / (fp + tp) if (fp + tp) != 0 else 0)\n","    npv.append(tn / (tn + fn) if (tn + fn) != 0 else 0)\n","\n","# ROC Curve\n","fpr, tpr, roc_auc = {}, {}, {}\n","for i in range(len(set(y_test))):\n","    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_prob[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Plot Confusion Matrix\n","plt.figure(figsize=(6, 5))\n","sns.heatmap(conf_matrix[::-1, ::-1], annot=True, fmt=\"d\", cmap=\"Blues\",\n","            xticklabels=le_group.classes_[::-1], yticklabels=le_group.classes_[::-1])\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# Plot ROC Curve\n","plt.figure(figsize=(7, 6))\n","for i in range(len(set(y_test))):\n","    plt.plot(fpr[i], tpr[i], label=f\"Class {le_group.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n","plt.plot([0, 1], [0, 1], \"k--\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n","\n","# Print evaluation results\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Cohen's Kappa: {kappa:.4f}\")\n","print(f\"Sensitivity: {sensitivity}\")\n","print(f\"Specificity: {specificity}\")\n","print(f\"False Discovery Rate (FDR): {fdr}\")\n","print(f\"Negative Predictive Value (NPV): {npv}\")\n","print(f\"Positive Predictive Value (PPV): {ppv}\")\n"]}]}