{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIIKWYtQy7ywuKZPs51ODY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SG7504/ML-Driven-EEG-Insights/blob/main/RF_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW-br2ulmK1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104cfe17-d745-4555-b1a6-eb8747171485"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-76cc2b90912f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix, classification_report,\n",
        "    cohen_kappa_score, roc_curve, auc\n",
        ")\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/drive/My Drive/EEG/final_data2.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Label Encoding\n",
        "class_labels = ['F', 'C', 'A']  # Define class order\n",
        "label_encoders = {}\n",
        "for col in ['Channel', 'Band', 'participant_id', 'Group']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Features and Target\n",
        "X = df[['Channel', 'Band', 'Dominant Frequency (Hz)', 'participant_id']]\n",
        "y = df['Group']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Manual Input for Number of Nodes\n",
        "num_nodes = int(input(\"Enter the number of nodes for the Random Forest Classifier: \"))\n",
        "\n",
        "def train_and_evaluate(num_nodes):\n",
        "    # Train Random Forest Classifier\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=num_nodes, random_state=42)\n",
        "    rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = rf.predict(X_train_scaled)\n",
        "    y_test_pred = rf.predict(X_test_scaled)\n",
        "\n",
        "    # Model Evaluation\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_test_pred, labels=[1, 0, 2])  # F, C, A order\n",
        "    kappa = cohen_kappa_score(y_test, y_test_pred)\n",
        "    report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "\n",
        "    # Compute Specificity, FDR, and other metrics\n",
        "    ppv_scores, npv_scores, fdr_scores, specificity_scores = [], [], [], []\n",
        "    for i in range(len(class_labels)):\n",
        "        tp = conf_matrix[i, i]\n",
        "        fp = sum(conf_matrix[:, i]) - tp\n",
        "        fn = sum(conf_matrix[i, :]) - tp\n",
        "        tn = conf_matrix.sum() - (tp + fp + fn)\n",
        "\n",
        "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
        "        fdr = fp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        ppv_scores.append(ppv)\n",
        "        npv_scores.append(npv)\n",
        "        fdr_scores.append(fdr)\n",
        "        specificity_scores.append(specificity)\n",
        "\n",
        "    mean_ppv = np.mean(ppv_scores)\n",
        "    mean_npv = np.mean(npv_scores)\n",
        "    mean_fdr = np.mean(fdr_scores)\n",
        "    mean_specificity = np.mean(specificity_scores)\n",
        "\n",
        "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Kappa Score: {kappa:.4f}\")\n",
        "    print(f\"Specificity: {mean_specificity:.4f}\")\n",
        "    print(f\"FDR: {mean_fdr:.4f}\")\n",
        "\n",
        "    # Print Class-wise Metrics\n",
        "    print(\"\\n### Class-wise Performance Metrics ###\")\n",
        "    print(f\"{'Class':<10} {'Precision':<10} {'Recall':<10} {'F1-score':<10} {'Support':<10}\")\n",
        "    print(\"-\" * 50)\n",
        "    for class_label, i in zip(class_labels, range(len(class_labels))):\n",
        "        precision = report[str(i)]['precision']\n",
        "        recall = report[str(i)]['recall']\n",
        "        f1_score = report[str(i)]['f1-score']\n",
        "        support = report[str(i)]['support']\n",
        "        print(f\"{class_label:<10} {precision:<10.4f} {recall:<10.4f} {f1_score:<10.4f} {support:<10.0f}\")\n",
        "\n",
        "    # Confusion Matrix Heatmap (F, C, A order)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['F', 'C', 'A'], yticklabels=['F', 'C', 'A'])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix (F, C, A)')\n",
        "    plt.show()\n",
        "\n",
        "    # Multi-Class ROC Curve (C, F, A original order)\n",
        "    y_test_bin = label_binarize(y_test, classes=[0, 1, 2])  # C, F, A original order\n",
        "    y_score = rf.predict_proba(X_test_scaled)\n",
        "    n_classes = y_test_bin.shape[1]\n",
        "\n",
        "    fpr, tpr, roc_auc = {}, {}, {}\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    colors = cycle(['blue', 'red', 'green'])\n",
        "\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'Class {class_labels[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    # Baseline diagonal\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "    plt.title('Multi-Class ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Train model with user input nodes\n",
        "train_and_evaluate(num_nodes)\n"
      ]
    }
  ]
}